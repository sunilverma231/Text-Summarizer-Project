# üöÄ Quick Start Guide - Text Summarizer with LoRA

## Prerequisites Check ‚úÖ
- Python 3.10+
- Conda environment activated: `conda activate textS`
- All dependencies installed: ‚úì
- Model files available: ‚úì
- Tokenizer available: ‚úì

## Option 1: Start the FastAPI Server

### Terminal Command
```bash
cd /Users/sunilverma/Text-Summarizer-Project
python app.py
```

### Expected Output
```
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

### Access Points
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

---

## Option 2: Make Predictions Programmatically

### Python Script
```python
import requests

# Make a prediction
text = "Your long text to summarize goes here..."
response = requests.get(
    "http://localhost:8000/predict",
    params={"text": text}
)

result = response.json()
print("Input:", result['input_text'])
print("Summary:", result['summary'])
```

### cURL Command
```bash
curl "http://localhost:8000/predict?text=Hello%20world%20is%20great"
```

---

## Option 3: Train New Model (with LoRA)

### Via API Endpoint
```bash
curl "http://localhost:8000/train"
# Or navigate to: http://localhost:8000/train in browser
```

### Via Terminal
```bash
python main.py
```

### Training Benefits with LoRA
- ‚ö° **80-90% faster** than full fine-tuning
- üíæ **4-10x smaller** memory requirement
- üéØ **Same accuracy** with minimal parameters
- ‚è±Ô∏è **~30-60 minutes** vs 4-6 hours

---

## API Endpoints Summary

| Method | Endpoint | Purpose |
|--------|----------|---------|
| GET | / | Redirect to /docs |
| GET | /docs | Swagger UI documentation |
| GET | /predict | Make predictions |
| GET | /train | Train new model |

### /predict Endpoint

**Parameters:**
- `text` (string, required): Text to summarize

**Example:**
```
GET /predict?text=Machine%20learning%20is%20powerful
```

**Response:**
```json
{
  "input_text": "Machine learning is powerful",
  "summary": "Machine learning is powerful ..."
}
```

---

## Troubleshooting

### Port 8000 Already in Use
```bash
# Kill existing process
pkill -f "python app.py"

# Or use a different port
python -c "
from fastapi import FastAPI
import uvicorn
from text_summarizer.pipeline.prediction import PredictionPipeline

app = FastAPI()
prediction_pipeline = PredictionPipeline()

@app.get('/predict')
def predict(text: str):
    summary = prediction_pipeline.predict(text)
    return {'input_text': text, 'summary': summary}

uvicorn.run(app, host='0.0.0.0', port=8001)  # Different port
"
```

### Model Loading Issues
```bash
# Test the pipeline manually
python test_pipeline.py
```

### CUDA/Memory Issues
The app uses CPU by default (macOS optimized). No changes needed.

---

## Files Reference

| File | Purpose |
|------|---------|
| `app.py` | FastAPI application entry point |
| `main.py` | Training pipeline entry point |
| `test_pipeline.py` | Dry-run test script |
| `LORA_MIGRATION.md` | LoRA implementation details |
| `DRY_RUN_REPORT.md` | Full test results |

---

## Next Steps

1. **Run the app:**
   ```bash
   python app.py
   ```

2. **Open Swagger UI:**
   ```
   http://localhost:8000/docs
   ```

3. **Test the API:**
   - Click "Try it out" on /predict endpoint
   - Enter sample text
   - See the summary

4. **Train with LoRA (optional):**
   - Click on /train endpoint, or
   - Run `python main.py` in another terminal

---

## Performance Tips

### For Better Summaries
- Use longer input texts (100+ words recommended)
- Break very long texts into sections
- Use clear, grammatically correct input

### For Faster API Response
- The model is loaded once at startup
- Predictions are cached when possible
- Subsequent predictions are faster (~<1s)

### For LoRA Training
- Training automatically uses LoRA for faster speed
- Default: 1 epoch on 40 samples = ~30 minutes
- Adjust in config if needed

---

## Additional Resources

- **Swagger Docs**: http://localhost:8000/docs (Interactive API testing)
- **LoRA Details**: See [LORA_MIGRATION.md](LORA_MIGRATION.md)
- **Test Results**: See [DRY_RUN_REPORT.md](DRY_RUN_REPORT.md)

---

**Status**: ‚úÖ Everything is ready to go!

Start with: `python app.py` üéâ
