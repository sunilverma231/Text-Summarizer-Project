{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d291820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CPU mode - MUST run this cell FIRST before any other cells\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "print(\"âœ“ Forcing CPU mode (MPS disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a924ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c13ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sunilverma/Text-Summarizer-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcb9bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sunilverma/Text-Summarizer-Project'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5108526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: str\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: int\n",
    "    gradient_accumulation_steps: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ca5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_summarizer.constants import *\n",
    "from text_summarizer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3877220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from text_summarizer.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from text_summarizer.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "    ):\n",
    "        # Convert relative paths to absolute\n",
    "        if not config_filepath.is_absolute():\n",
    "            config_filepath = Path(os.getcwd()) / config_filepath\n",
    "        if not params_filepath.is_absolute():\n",
    "            params_filepath = Path(os.getcwd()) / params_filepath\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        model_trainer_config = self.config.model_trainer\n",
    "        training_args = self.params.TrainingArguments\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(model_trainer_config.root_dir),\n",
    "            data_path=Path(model_trainer_config.data_path),\n",
    "            model_ckpt=Path(model_trainer_config.model_ckpt),\n",
    "            num_train_epochs=training_args.num_train_epochs,\n",
    "            warmup_steps=training_args.warmup_steps,\n",
    "            per_device_train_batch_size=training_args.per_device_train_batch_size,\n",
    "            weight_decay=training_args.weight_decay,\n",
    "            logging_steps=training_args.logging_steps,\n",
    "            evaluation_strategy=training_args.evaluation_strategy,\n",
    "            eval_steps=training_args.eval_steps,\n",
    "            save_steps=training_args.save_steps,\n",
    "            gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n",
    "        )\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc371668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cde2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# trainer_args = TrainingArguments(\n",
    "#     output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "#     per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "#     weight_decay=0.01, logging_steps=10,\n",
    "#     eval_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "#     gradient_accumulation_steps=16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38957065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer: \n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        # Force CPU device explicitly\n",
    "        device = \"cpu\"\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Ensure Transformers logs show up and tqdm is enabled\n",
    "        try:\n",
    "            from transformers.utils import logging as hf_logging\n",
    "            hf_logging.set_verbosity_info()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt, use_safetensors=True)\n",
    "        \n",
    "        # Explicitly move model to CPU\n",
    "        model = model.to(device)\n",
    "        \n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "        data_collator = seq2seq_data_collator\n",
    "\n",
    "        # Loading the dataset from the data path\n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "        \n",
    "        # Use 40 samples - calibrated for ~1 hour training on CPU\n",
    "        train_dataset = dataset_samsum_pt['test'].select(range(min(40, len(dataset_samsum_pt['test']))))\n",
    "        eval_dataset = dataset_samsum_pt['validation'].select(range(min(10, len(dataset_samsum_pt['validation']))))\n",
    "        print(f\"Training on {len(train_dataset)} samples\")\n",
    "        print(f\"Evaluating on {len(eval_dataset)} samples\")\n",
    "\n",
    "        # Training configuration - optimized for ~1 hour completion\n",
    "        trainer_args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir,\n",
    "            num_train_epochs=1,\n",
    "            warmup_steps=10,\n",
    "            per_device_train_batch_size=1,\n",
    "            weight_decay=0.01,\n",
    "            logging_strategy='steps',\n",
    "            logging_steps=5,\n",
    "            disable_tqdm=False,\n",
    "            report_to='none',\n",
    "            eval_strategy='steps',\n",
    "            eval_steps=20,\n",
    "            save_steps=int(1e6),\n",
    "            gradient_accumulation_steps=4,\n",
    "            no_cuda=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=trainer_args,\n",
    "            tokenizer=tokenizer,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "        train_output = trainer.train()\n",
    "        \n",
    "        try:\n",
    "            steps = int(train_output.global_step)\n",
    "            print(f\"Training finished. Total steps: {steps}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\"Training completed!\")\n",
    "\n",
    "        # Saving the model after training\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir, \"pegasus-samsum-model\"))\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir, \"tokenizer\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd70da8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-19 10:38:32,754: INFO: common: yaml file: /Users/sunilverma/Text-Summarizer-Project/config/config.yaml loaded successfully\n",
      "2025-12-19 10:38:32,765: INFO: common: yaml file: /Users/sunilverma/Text-Summarizer-Project/params.yaml loaded successfully\n",
      "2025-12-19 10:38:32,767: INFO: common: created directory at: artifacts\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 32,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 32,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 32,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 32,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "loading weights file model.safetensors from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/7db4e727842ad86cc5cdfeaef4d14c6fb2b46511/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 32,\n",
      "  \"num_beams\": 8,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file generation_config.json from cache at /Users/sunilverma/.cache/huggingface/hub/models--google--pegasus-cnn_dailymail/snapshots/40d588fdab0cc077b80d950b300bf66ad3c75b92/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 32,\n",
      "  \"num_beams\": 8,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Could not locate the custom_generate/generate.py inside google/pegasus-cnn_dailymail.\n",
      "/Users/sunilverma/opt/anaconda3/envs/textS/lib/python3.10/site-packages/transformers/training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n",
      "/var/folders/9m/ztkm5bns0x1b521x6wdpd4640000gn/T/ipykernel_36612/651504547.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "The following columns in the Training set don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: id, summary, dialogue. If id, summary, dialogue are not expected by `PegasusForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "  Number of trainable parameters = 568,699,904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3 samples for portfolio demo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 05:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.338200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to artifacts/model_trainer/checkpoint-3\n",
      "/Users/sunilverma/opt/anaconda3/envs/textS/lib/python3.10/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "Configuration saved in artifacts/model_trainer/checkpoint-3/config.json\n",
      "Configuration saved in artifacts/model_trainer/checkpoint-3/generation_config.json\n",
      "Model weights saved in artifacts/model_trainer/checkpoint-3/model.safetensors\n",
      "tokenizer config file saved in artifacts/model_trainer/checkpoint-3/tokenizer_config.json\n",
      "Special tokens file saved in artifacts/model_trainer/checkpoint-3/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Configuration saved in artifacts/model_trainer/pegasus-samsum-model/config.json\n",
      "Configuration saved in artifacts/model_trainer/pegasus-samsum-model/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Total steps: 3\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in artifacts/model_trainer/pegasus-samsum-model/model.safetensors\n",
      "tokenizer config file saved in artifacts/model_trainer/tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in artifacts/model_trainer/tokenizer/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e: \n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47234ced",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff65b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
